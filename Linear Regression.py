
# coding: utf-8

# # Linear Regression

# Linear Regression is used to generate model that defines the relationship between the dependent and independent varibales. It creates a best fitted line that is generated by minimizing the sum of squares with repect to the vertical deviation.If a point is excatly on the line then the vertical deviation will be zero.

# In[1]:


import pandas as pd
import matplotlib.pyplot as plt 
get_ipython().run_line_magic('matplotlib', 'inline')
import seaborn as sns


# In[2]:


df = pd.read_csv(r'C:\Users\tanvi\Desktop\ML Datasets\housing.csv') #this data set is available online.


# In[3]:


df.head()# this will provide you with starting 5 contents.


# In[4]:


df.info()# this is beneficial to locate if the datatype is correct and if there are any null values.


# In[5]:


df['Price'].nunique()#gives only the number of unique values


# In[6]:


df['Address'].nunique()


# In[7]:


sns.pairplot(df)#as the name suggest it creates various possibilty of creating graphs to have a basic idea of the movemnet of data and how they react to each other.


# In[8]:


sns.pairplot(df,kind='reg') #by including the kind as 'reg', will create a regression line to summarise the slope.


# In[9]:


df.columns


# In[10]:


X = df[['Avg. Area Income', 'Avg. Area House Age', 'Avg. Area Number of Rooms',
        'Area Population']]
y = df['Price']


# In[11]:


from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3, 
                                                    random_state=101)##we import train_test_split to break the data into two datasets.One from which we create the model, and other one is test data where we test the analysis to verify the model. If the model bulit is satisfactory then it can helpful in further analysis such data.


# In[13]:


X_test.info()


# In[14]:


from sklearn.linear_model import LinearRegression


# In[15]:


model = LinearRegression().fit(X_train, y_train)


# ## Evaluate Model

# In[16]:


pred = model.predict(X_test)


# In[17]:


plt.scatter(y_test, pred)


# In[18]:


pred[0]


# In[23]:


y_test.values[0]


# In[24]:


100*(y_test.values[0]-pred[0])/y_test.values[0]


# In[26]:


from sklearn.metrics import mean_absolute_error, mean_squared_error


# In[30]:


model.score(X_test,y_test)*100


# In[31]:


print(mean_absolute_error(y_test,pred))


# In[33]:


cdf = pd.DataFrame(model.coef_, index = X.columns, columns=['Coeffecients'])
cdf


# From this we can understand the relationship and actually wi=hich factors affect the most. Although the model score is good. 
